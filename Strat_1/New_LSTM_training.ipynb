{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM MODEL BUILDING 2025 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import Preprocessing_functions as pf  \n",
    "#import LSTM_Architecture as ls \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from datetime import datetime \n",
    "from pathlib import Path\n",
    "#from Preprocessing_functions import min_max_scaling, create_multivariate_rnn_data, accuracy_fn, format_idx_date\n",
    "#from torch.utils.data import DataLoader #, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for LSTM model\n",
    "def prepare_data(data, sequence_length):\n",
    "    import numpy as np\n",
    "    y = data.pop('labels')\n",
    "    \n",
    "    data = data.dropna()\n",
    "    \n",
    "    features = list(data.columns)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(data[features])\n",
    "    \n",
    "     # Create sequences\n",
    "    X, y_seq = [], []\n",
    "    for i in range(len(X_scaled) - sequence_length):\n",
    "        X.append(X_scaled[i:i + sequence_length])\n",
    "        y_seq.append(y.iloc[i + sequence_length - 1])\n",
    "\n",
    "    return np.array(X), np.array(y_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): The number of input features.\n",
    "            hidden_sizes (list): A list of hidden sizes for each LSTM layer (e.g., [128, 64, 32]).\n",
    "            output_size (int): The number of output features.\n",
    "        \"\"\"\n",
    "        super(CustomLSTMModel, self).__init__()\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        \n",
    "        # Define the first LSTM layer\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
    "        \n",
    "        # Define subsequent LSTM layers\n",
    "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
    "        self.lstm3 = nn.LSTM(hidden_sizes[1], hidden_sizes[2], batch_first=True)\n",
    "        \n",
    "        # Fully connected layer for final output\n",
    "        self.fc = nn.Linear(hidden_sizes[2], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the first LSTM layer\n",
    "        out, _ = self.lstm1(x)\n",
    "        \n",
    "        # Pass through the second LSTM layer\n",
    "        out, _ = self.lstm2(out)\n",
    "        \n",
    "        # Pass through the third LSTM layer\n",
    "        out, _ = self.lstm3(out)\n",
    "        \n",
    "        # Pass the final output through the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time-step's output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CustomLSTMModel_2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_sizes, output_size):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): The number of input features.\n",
    "            hidden_sizes (list): A list of hidden sizes for each LSTM layer (e.g., [128, 64]).\n",
    "            output_size (int): The number of output features.\n",
    "        \"\"\"\n",
    "        super(CustomLSTMModel_2, self).__init__()\n",
    "        \n",
    "        # Define the first LSTM layer\n",
    "        self.lstm1 = nn.LSTM(input_size, hidden_sizes[0], batch_first=True)\n",
    "        \n",
    "        # Define the second LSTM layer\n",
    "        self.lstm2 = nn.LSTM(hidden_sizes[0], hidden_sizes[1], batch_first=True)\n",
    "        \n",
    "        # Fully connected layer for final output\n",
    "        self.fc = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the first LSTM layer\n",
    "        out, _ = self.lstm1(x)\n",
    "        \n",
    "        # Pass through the second LSTM layer\n",
    "        out, _ = self.lstm2(out)\n",
    "        \n",
    "        # Pass the final output through the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])  # Use the last time-step's output\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames for model building:  ['df_SPY_k3_202402012133.parquet']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Data/SPY/df/df_SPY_k3_202402012133.parquet'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ticker = \"SPY\"\n",
    "\n",
    "# LOAD DF FOR MODEL BUILDING \n",
    "FILE_PATH = f\"Data/{ticker}/df/\"\n",
    "DF_FILES = os.listdir(FILE_PATH)\n",
    "DF_FILES.remove('Junk')\n",
    "print(\"DataFrames for model building: \", DF_FILES)\n",
    "idx = 0 if len(DF_FILES) < 2 else int(input(\"Select file index: \"))\n",
    "DF_NAME = DF_FILES[idx] \n",
    "FILE_PATH_NAME = FILE_PATH + DF_NAME\n",
    "FILE_PATH_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>open_low</th>\n",
       "      <th>open_close</th>\n",
       "      <th>gap</th>\n",
       "      <th>open_high</th>\n",
       "      <th>low_close</th>\n",
       "      <th>high_close</th>\n",
       "      <th>high_low</th>\n",
       "      <th>Dividends</th>\n",
       "      <th>Volume</th>\n",
       "      <th>...</th>\n",
       "      <th>SPY_mom3</th>\n",
       "      <th>SPY_mom4</th>\n",
       "      <th>SPY_mom5</th>\n",
       "      <th>SPY_mom10</th>\n",
       "      <th>SPY_mom15</th>\n",
       "      <th>SPY_mom20</th>\n",
       "      <th>SPY_mom60</th>\n",
       "      <th>SPY_mom120</th>\n",
       "      <th>SPY_mom180</th>\n",
       "      <th>SPY_mom240</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-02-01</th>\n",
       "      <td>1</td>\n",
       "      <td>0.171265</td>\n",
       "      <td>-0.538555</td>\n",
       "      <td>0.362409</td>\n",
       "      <td>-0.744898</td>\n",
       "      <td>-0.711038</td>\n",
       "      <td>-0.204817</td>\n",
       "      <td>0.909389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59327438</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.82</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.24</td>\n",
       "      <td>3.94</td>\n",
       "      <td>12.54</td>\n",
       "      <td>10.10</td>\n",
       "      <td>19.31</td>\n",
       "      <td>21.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-31</th>\n",
       "      <td>0</td>\n",
       "      <td>1.178830</td>\n",
       "      <td>1.174737</td>\n",
       "      <td>-0.462425</td>\n",
       "      <td>-0.094143</td>\n",
       "      <td>-0.004142</td>\n",
       "      <td>-1.267686</td>\n",
       "      <td>1.271776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>126011100</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.93</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>-0.52</td>\n",
       "      <td>2.24</td>\n",
       "      <td>1.90</td>\n",
       "      <td>2.16</td>\n",
       "      <td>12.55</td>\n",
       "      <td>9.15</td>\n",
       "      <td>18.65</td>\n",
       "      <td>18.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-30</th>\n",
       "      <td>2</td>\n",
       "      <td>0.091732</td>\n",
       "      <td>-0.067270</td>\n",
       "      <td>-0.144523</td>\n",
       "      <td>-0.216080</td>\n",
       "      <td>-0.159148</td>\n",
       "      <td>-0.148489</td>\n",
       "      <td>0.307148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58618400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.36</td>\n",
       "      <td>3.43</td>\n",
       "      <td>3.28</td>\n",
       "      <td>16.61</td>\n",
       "      <td>10.22</td>\n",
       "      <td>20.46</td>\n",
       "      <td>20.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-29</th>\n",
       "      <td>1</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>-0.725811</td>\n",
       "      <td>0.065653</td>\n",
       "      <td>-0.756566</td>\n",
       "      <td>-0.841595</td>\n",
       "      <td>-0.030524</td>\n",
       "      <td>0.864841</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61322800</td>\n",
       "      <td>...</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.62</td>\n",
       "      <td>3.06</td>\n",
       "      <td>4.99</td>\n",
       "      <td>3.06</td>\n",
       "      <td>17.95</td>\n",
       "      <td>9.83</td>\n",
       "      <td>20.34</td>\n",
       "      <td>20.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-01-26</th>\n",
       "      <td>2</td>\n",
       "      <td>0.215345</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>-0.090158</td>\n",
       "      <td>-0.313788</td>\n",
       "      <td>-0.178814</td>\n",
       "      <td>-0.349607</td>\n",
       "      <td>0.527478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76606300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1.03</td>\n",
       "      <td>2.32</td>\n",
       "      <td>4.31</td>\n",
       "      <td>2.29</td>\n",
       "      <td>17.76</td>\n",
       "      <td>9.92</td>\n",
       "      <td>19.96</td>\n",
       "      <td>21.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            labels  open_low  open_close       gap  open_high  low_close  \\\n",
       "Date                                                                       \n",
       "2024-02-01       1  0.171265   -0.538555  0.362409  -0.744898  -0.711038   \n",
       "2024-01-31       0  1.178830    1.174737 -0.462425  -0.094143  -0.004142   \n",
       "2024-01-30       2  0.091732   -0.067270 -0.144523  -0.216080  -0.159148   \n",
       "2024-01-29       1  0.114818   -0.725811  0.065653  -0.756566  -0.841595   \n",
       "2024-01-26       2  0.215345    0.036916 -0.090158  -0.313788  -0.178814   \n",
       "\n",
       "            high_close  high_low  Dividends     Volume  ...  SPY_mom3  \\\n",
       "Date                                                    ...             \n",
       "2024-02-01   -0.204817  0.909389        0.0   59327438  ...     -0.82   \n",
       "2024-01-31   -1.267686  1.271776        0.0  126011100  ...     -0.93   \n",
       "2024-01-30   -0.148489  0.307148        0.0   58618400  ...      0.59   \n",
       "2024-01-29   -0.030524  0.864841        0.0   61322800  ...      1.21   \n",
       "2024-01-26   -0.349607  0.527478        0.0   76606300  ...      0.53   \n",
       "\n",
       "            SPY_mom4  SPY_mom5  SPY_mom10  SPY_mom15  SPY_mom20  SPY_mom60  \\\n",
       "Date                                                                         \n",
       "2024-02-01     -0.03     -0.16       2.26       2.24       3.94      12.54   \n",
       "2024-01-31     -1.06     -0.52       2.24       1.90       2.16      12.55   \n",
       "2024-01-30      1.13      1.24       3.36       3.43       3.28      16.61   \n",
       "2024-01-29      1.32      1.62       3.06       4.99       3.06      17.95   \n",
       "2024-01-26      0.82      1.03       2.32       4.31       2.29      17.76   \n",
       "\n",
       "            SPY_mom120  SPY_mom180  SPY_mom240  \n",
       "Date                                            \n",
       "2024-02-01       10.10       19.31       21.15  \n",
       "2024-01-31        9.15       18.65       18.42  \n",
       "2024-01-30       10.22       20.46       20.77  \n",
       "2024-01-29        9.83       20.34       20.81  \n",
       "2024-01-26        9.92       19.96       21.27  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model = pd.read_parquet(FILE_PATH_NAME)\n",
    "df_model = df_model.reset_index()\n",
    "df_model['Date'] = pd.to_datetime(df_model['Date']).dt.date\n",
    "df_model = df_model.set_index(\"Date\")\n",
    "df_model = df_model.sort_index(ascending=False)\n",
    "\n",
    "df_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data for LSTM model\n",
    "\n",
    "sequence_length = 3\n",
    "data = df_model.copy()\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "y = data.pop('labels')\n",
    "\n",
    "data = data.dropna()\n",
    "\n",
    "features = list(data.columns)\n",
    "#scaler = StandardScaler()\n",
    "#X_scaled = scaler.fit_transform(data[features])\n",
    "X_scaled = data[features]\n",
    "\n",
    "#np.array(X), np.array(y_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Create sequences\n",
    "X, y_seq = [], []\n",
    "for i in range(len(X_scaled) - sequence_length):\n",
    "    X.append(X_scaled[i:i + sequence_length])\n",
    "    y_seq.append(y.iloc[i + sequence_length - 1])\n",
    "\n",
    "\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "SEQUENCE_LENGTH = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X, y = prepare_data(df_model, SEQUENCE_LENGTH)\n",
    "\n",
    "print('X shape: ', X.shape)\n",
    "print('y shape: ', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "INPUT_SIZE = X.shape[2]\n",
    "HIDDEN_SIZES = [128,64,32] # for custom lstm \n",
    "HIDDEN_SIZES = [32,16] # for custom lstm \n",
    "OUTPUT_SIZE = 3\n",
    "EPOCHS = int(5e2)\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size_pct = 0.7\n",
    "\n",
    "train_size = int(train_size_pct * X.shape[0])\n",
    "\n",
    "X_train = X[ :train_size, :]\n",
    "X_test = X[train_size :, :]\n",
    "\n",
    "y_train = y[:train_size]\n",
    "y_test = y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training set start date: ', df_model.iloc[ :train_size, :].index.min())\n",
    "print('Training set end date: ', df_model.iloc[ :train_size, :].index.max())\n",
    "print('Test set start date: ', df_model.iloc[train_size :, :].index.min())\n",
    "print('Test set end date: ', df_model.iloc[train_size :, :].index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CustomLSTMModel_2(INPUT_SIZE, HIDDEN_SIZES, OUTPUT_SIZE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {}\n",
    "\n",
    "best_epoch = 0\n",
    "best_accuracy = 0 \n",
    "best_model_name = ''\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Evaluate on training set\n",
    "    with torch.no_grad():\n",
    "        train_predictions = outputs.argmax(dim=1)\n",
    "        train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "        train_precision = precision_score(y_train, train_predictions, average='weighted', zero_division=0)\n",
    "        train_recall = recall_score(y_train, train_predictions, average='weighted', zero_division=0)\n",
    "        train_f1 = f1_score(y_train, train_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_test)\n",
    "        val_predictions = val_outputs.argmax(dim=1)\n",
    "        val_accuracy = accuracy_score(y_test, val_predictions)\n",
    "        val_precision = precision_score(y_test, val_predictions, average='weighted', zero_division=0)\n",
    "        val_recall = recall_score(y_test, val_predictions, average='weighted', zero_division=0)\n",
    "        val_f1 = f1_score(y_test, val_predictions, average='weighted', zero_division=0)\n",
    "\n",
    "    \n",
    "    if val_accuracy > best_accuracy: \n",
    "        \n",
    "        best_accuracy = val_accuracy\n",
    "        best_epoch = epoch\n",
    "        \n",
    "        DATE = datetime.today().strftime('%Y%m%d%H%M')\n",
    "        MODEL_PATH = Path(f\"lstm_models/Testing/{ticker}\")\n",
    "        MODEL_PATH.mkdir(parents = True, exist_ok = True)\n",
    "        \n",
    "        # CREATE MODEL SAVE PATH\n",
    "        MODEL_NAME = f\"LSTM_Class_Epoch_{epoch}_TestAcc_{val_accuracy:.2f}_TrainAcc_{train_accuracy:.2F}_{DATE}\"\n",
    "        MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "        best_model_pathname = MODEL_SAVE_PATH\n",
    "        # SAVE MODEL STATE DICT\n",
    "        print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "        torch.save(obj = model.state_dict(), f = MODEL_SAVE_PATH)\n",
    "        \n",
    "        \n",
    "    \n",
    "    results[epoch]  = [(train_accuracy, val_accuracy)]\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}], Train Accuracy: {train_accuracy:.6f}, Train F1: {train_f1:.4f}, Val Accuracy: {val_accuracy:.6f}, Val F1: {val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_pathname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LOAD THE BEST MDOEL\n",
    "# LOAD LSTM MODEL STATE DICT  \n",
    "model.load_state_dict(torch.load(f = best_model_pathname ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(val_predictions).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### plot training \n",
    "res = pd.DataFrame(results.values())\n",
    "res.columns = ['tuple']\n",
    "\n",
    "res['train_acc'] = res['tuple'].apply(lambda x : x[0])\n",
    "res['test_acc'] = res['tuple'].apply(lambda x : x[1])\n",
    "\n",
    "del res['tuple']\n",
    "res.index = results.keys()\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(res.index, res['train_acc'], color = 'red', label = 'Train')\n",
    "plt.plot(res.index, res['test_acc'], color = 'blue', label = 'Test')\n",
    "plt.title('Train vs Test Accucacy per Epoch')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing outside of training DF (and out of training loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pf.downlaod_symbol_data(ticker, '120mo')\n",
    "df_test = pf.create_momentum_feat(df_test, ticker).dropna()\n",
    "df_test = df_test[df_test.index > '2024-02-01']\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "### LOAD KMEANS MODEL ###\n",
    "KMEANS_PATH = f\"kmeans_models/{ticker}/\"\n",
    "KMEANS_MODEL_PATH = os.listdir(KMEANS_PATH)\n",
    "try:\n",
    "    KMEANS_MODEL_PATH.remove('Junk')\n",
    "except ValueError:\n",
    "    print(' ')    \n",
    "\n",
    "print(KMEANS_MODEL_PATH)\n",
    "idx = 0 if len(KMEANS_MODEL_PATH) < 2 else int(input(\"Select file index: \"))\n",
    "KMEANS_NAME = KMEANS_MODEL_PATH[idx]\n",
    "print(\"Chosen K_MEANS MODEL file: \", KMEANS_NAME)\n",
    "FILE = KMEANS_PATH + KMEANS_NAME\n",
    "loaded_kmeans = joblib.load(FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ASSIGN CLUSTER TO OBSERVATION ###\n",
    "data = df_test[[\"open_low\", \"open_close\", \"gap\"]].dropna()\n",
    "print(data.shape)\n",
    "k_predictions = pd.DataFrame(loaded_kmeans.predict(data), columns = [\"labels\"], index = data.index)\n",
    "#data = data.merge(k_predictions, left_index = True, right_index = True)#.reset_index()\n",
    "k_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test.merge(k_predictions, left_index=True, right_index= True, how = 'left')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_test[list(df_model.columns) + ['labels']]\n",
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = prepare_data(df_test, SEQUENCE_LENGTH)\n",
    "\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_outputs = model(X_test)\n",
    "    val_predictions = val_outputs.argmax(dim=1)\n",
    "    val_accuracy = accuracy_score(y_test, val_predictions)\n",
    "    val_precision = precision_score(y_test, val_predictions, average='weighted', zero_division=0)\n",
    "    val_recall = recall_score(y_test, val_predictions, average='weighted', zero_division=0)\n",
    "    val_f1 = f1_score(y_test, val_predictions, average='weighted', zero_division=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: ' , round(val_accuracy, 2))\n",
    "print('Precision: ' , round(val_precision, 2))\n",
    "print('Recall: ', round(val_recall, 2))\n",
    "print('F1: ', round(val_f1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
